import os
import glob
import subprocess
from pathlib import Path
import whisper

# Ð”Ð»Ñ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð½Ð°Ð¼ Ð½ÑƒÐ¶Ð½Ð¾ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸, ÐµÑÐ»Ð¸ Ð¸Ñ… Ð½ÐµÑ‚:
# pip install openai-whisper ffmpeg-python

def extract_audio(video_path, output_audio_path):
    """
    Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð¾Ñ€Ð¾Ð¶ÐºÑƒ Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾ Ñ„Ð°Ð¹Ð»Ð° Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ffmpeg
    """
    print(f"ðŸŽ¬ Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸Ð· {video_path}...")
    # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ subprocess Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° ffmpeg
    command = [
        "ffmpeg", 
        "-i", video_path,  # Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ñ„Ð°Ð¹Ð»
        "-q:a", "0",       # ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ (0 - Ð»ÑƒÑ‡ÑˆÐµÐµ)
        "-map", "a",       # Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾Ðº
        "-y",              # Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
        output_audio_path  # Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð°Ð¹Ð»
    ]
    subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    print(f"âœ… ÐÑƒÐ´Ð¸Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¾ Ð² {output_audio_path}")

def transcribe_audio(audio_path, output_text_path):
    """
    Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€ÑƒÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð°Ð¹Ð» Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Whisper (medium)
    """
    print(f"ðŸŽ¤ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Whisper (medium)...")
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ medium Ð¼Ð¾Ð´ÐµÐ»ÑŒ (ÑÑ‚Ð¾ Ð·Ð°Ð¹Ð¼ÐµÑ‚ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐµ)
    model = whisper.load_model("medium")
    
    print(f"ðŸŽ§ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸Ð· Ð°ÑƒÐ´Ð¸Ð¾ {audio_path}...")
    # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
    result = model.transcribe(audio_path)
    
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°
    transcription = result["text"]
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
    with open(output_text_path, "w", encoding="utf-8") as text_file:
        text_file.write(transcription)
    
    print(f"âœ… Ð¢ÐµÐºÑÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½ Ð² {output_text_path}")
    return transcription

def main():
    # ÐÐ°Ð¹Ñ‚Ð¸ ÐµÐ´Ð¸Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ mp4 Ñ„Ð°Ð¹Ð» Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
    mp4_files = glob.glob("*.mp4")
    
    if not mp4_files:
        print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: MP4 Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸!")
        return
    
    if len(mp4_files) > 1:
        print(f"âš ï¸ Ð’Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ: ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ MP4 Ñ„Ð°Ð¹Ð»Ð¾Ð². Ð‘ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½ Ð¿ÐµÑ€Ð²Ñ‹Ð¹: {mp4_files[0]}")
    
    video_path = mp4_files[0]
    base_name = Path(video_path).stem
    
    # ÐŸÑƒÑ‚Ð¸ Ð´Ð»Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
    audio_path = f"{base_name}.mp3"
    text_path = f"{base_name}_transcription.txt"
    
    # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð°ÑƒÐ´Ð¸Ð¾
    extract_audio(video_path, audio_path)
    
    # Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð°ÑƒÐ´Ð¸Ð¾
    transcription = transcribe_audio(audio_path, text_path)
    
    print("\n" + "="*50)
    print(f"ðŸŽ‰ Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² Ñ„Ð°Ð¹Ð» {text_path}")
    print(f"ðŸ’¾ Ð Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð°Ð¹Ð»Ð° Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸: {os.path.getsize(text_path)} Ð±Ð°Ð¹Ñ‚")
    print(f"ðŸ“ ÐŸÐµÑ€Ð²Ñ‹Ðµ 150 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸:")
    print("-"*50)
    print(transcription[:150] + "..." if len(transcription) > 150 else transcription)
    print("="*50)

if __name__ == "__main__":
    main()
